# 敏感内容审查

我们在与 AI 应用交互的过程中，往往在内容安全性，用户体验，法律法规等方面有较为苛刻的要求，此时我们需要“敏感词审查”功能，来为终端用户创造一个更好的交互环境。 在提示词编排页面，点击“添加功能”，找到底部的工具箱“内容审核”：

<figure><img src="../../../.gitbook/assets/moderation1.png" alt=""><figcaption><p>Content moderation</p></figcaption></figure>

### 功能一：调用 OpenAI Moderation API

OpenAI 和大多数 LLM 公司提供的模型，都带有内容审查功能，确保不会输出包含有争议的内容，比如暴力，性和非法行为，并且 OpenAI 还开放了这种内容审查能力，具体可以参考 [platform.openai.com](https://platform.openai.com/docs/guides/moderation/overview) 。现在你也可以直接在 Dify 上调用 OpenAI Moderation API，你可以审核输入内容或输出内容，只要输入对应的“预设回复”即可。

<figure><img src="../../../.gitbook/assets/moderation2.png" alt=""><figcaption><p>OpenAI Moderation API</p></figcaption></figure>

### 功能二：自定义关键词

开发者可以自定义需要审查的敏感词，比如把“kill”作为关键词，在用户输入的时候作审核动作，要求预设回复内容为“The content is violating usage policies.”可以预见的结果是当用户在终端输入包含“kill”的语料片段，就会触发敏感词审查工具，返回预设回复内容。

<figure><img src="../../../.gitbook/assets/moderation3.png" alt=""><figcaption><p>Keywords</p></figcaption></figure>

### 功能三： 敏感词审查 Moderation 扩展

不同的企业内部往往有着不同的敏感词审查机制，企业在开发自己的 AI 应用如企业内部知识库 ChatBot，需要对员工输入的查询内容作敏感词审查。为此，开发者可以根据自己企业内部的敏感词审查机制写一个 API 扩展，具体可参考 [moderation.md](../../extension/api-based-extension/moderation.md "mention")，从而在 Dify 上调用，实现敏感词审查的高度自定义和隐私保护。

<figure><img src="../../../.gitbook/assets/moderation_settings.png" alt=""><figcaption><p>Moderation Settings</p></figcaption></figure>

比如我们在自己的本地服务中自定义敏感词审查规则：不能查询有关美国总统的名字的问题。当用户在`query`变量输入"Trump"，则在对话时会返回 "Your content violates our usage policy." 测试效果如下：

<figure><img src="../../../.gitbook/assets/moderation_tet.png" alt=""><figcaption><p>Moderation Test</p></figcaption></figure>
